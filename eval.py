import argparse
import os
from scipy import io
import torch
import timm
import numpy as np
import cv2
import torch.nn as nn
from torchvision import transforms

def generate_mask(img_height, img_width, radius, center_x, center_y):
    y, x = np.ogrid[0:img_height, 0:img_width]
    # circle mask
    mask = (x - center_x) ** 2 + (y - center_y) ** 2 <= radius ** 2
    return mask

def parse_arguments():
    parser = argparse.ArgumentParser(description="training codes")
    parser.add_argument("--output", type=str, default="../results/model_default", help="Path to save checkpoint.")
    parser.add_argument("--input", type=str, default="../mat/NAC_train", help="Input images.")
    parser.add_argument("--target", type=str, default="../mat/CT_train", help="Target images.")
    parser.add_argument("--model", type=str, default="../models/model_default/checkpoint/latest.pth")
    args = parser.parse_args()
    return args

def init_status(args):
    os.makedirs(args.output, exist_ok=True)
    os.makedirs(os.path.join(args.output, "predict"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "target"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "origin"), exist_ok=True)

# ðŸ” 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹
class SwinPETModel(nn.Module):
    def __init__(self):
        super(SwinPETModel, self).__init__()
        self.model = timm.create_model('swin_base_patch4_window7_224', pretrained=False, patch_size=1)
        
        # Swin Transformer çš„ head ä¿®æ”¹ä¸ºåƒç´ çº§è¾“å‡º
        self.model.head = nn.Identity()
        
        # æ–°çš„å·ç§¯ headï¼Œæ¢å¤ç‰¹å¾å›¾ä¸º 224x224 çš„åƒç´ çº§è¾“å‡º
        self.upsample_conv = nn.Sequential(
            nn.Conv2d(1024, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 1, kernel_size=1),
            nn.ConvTranspose2d(1, 1, kernel_size=8, stride=8)  # å°† 7x7 æ”¾å¤§åˆ° 224x224
        )

    def forward(self, x):
        x = self.model.forward_features(x)
        x = x.permute(0, 3, 1, 2) 
        x = self.upsample_conv(x)
        return x

def eval(args):
    # ðŸ§  2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹æƒé‡
    model = SwinPETModel()
    # åŠ è½½æ¨¡åž‹æƒé‡å­—å…¸
    checkpoint = torch.load(args.model, map_location='cpu')

    # å¤„ç† state_dictï¼Œç§»é™¤ 'module.' å‰ç¼€
    new_state_dict = {}
    for k, v in checkpoint.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # åŽ»æŽ‰ 'module.' å‰ç¼€
        else:
            new_state_dict[k] = v

    # å°†æ–° state_dict åŠ è½½åˆ°æ¨¡åž‹ä¸­
    model.load_state_dict(new_state_dict)
    model.eval()  # è®¾ä¸ºæŽ¨ç†æ¨¡å¼
    
    # ðŸŒˆ 3. å®šä¹‰å›¾åƒé¢„å¤„ç†æ–¹æ³• (ä¸Žè®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
    transform = transforms.Compose([
        transforms.Resize((224, 224))
    ])
    
    input_folder = args.input  # å­˜æ”¾ .mat æ–‡ä»¶çš„æ–‡ä»¶å¤¹
    target_folder = args.target  # æœŸæœ›è¾“å‡ºå›¾ç‰‡
    output_folder = args.output  # é¢„æµ‹è¾“å‡ºå›¾ç‰‡çš„ä¿å­˜æ–‡ä»¶å¤¹
    mask = generate_mask(256, 256, 128, 128, 128)
    
    for file_name in os.listdir(input_folder):
        input_path = os.path.join(input_folder, file_name)
        
        # è¯»å– .mat æ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ® (å‡è®¾ img å­—æ®µåŒ…å« 256x256 çš„ç°åº¦å›¾ï¼ŒèŒƒå›´ä¸º 0-1)
        input_img = io.loadmat(input_path)['img'].astype('float32')
        input_img = input_img * mask
        input_img = np.repeat(input_img[:,:,np.newaxis], 3, axis=2)
        input_img = torch.from_numpy(input_img).permute(2, 0, 1).float()
        input_img = transform(input_img).unsqueeze(0)
        
        # è¿›è¡ŒæŽ¨ç†
        with torch.no_grad():
            output = model(input_img)
        
        # å¤„ç†è¾“å‡º (è½¬æ¢ä¸ºå›¾åƒ)
        output = output.squeeze(0).squeeze(0).numpy()  # å½¢çŠ¶ (224, 224)
        output = (output - output.min()) / (output.max() - output.min())  # å½’ä¸€åŒ–åˆ° 0-1
        output = (output * 255).astype(np.uint8)
        
        # ä¿å­˜è¾“å‡ºå›¾åƒ
        output_path = os.path.join(output_folder, "predict", f"{os.path.splitext(file_name)[0]}.png")
        cv2.imwrite(output_path, output)
        
        print(f"å¤„ç†å®Œæˆ: {file_name} -> {output_path}")

if __name__ == "__main__":
    args = parse_arguments()
    init_status(args)
    eval(args)