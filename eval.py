import argparse
import os
from scipy import io
import torch
import timm
import numpy as np
import cv2
import torch.nn as nn
from torchvision import transforms
from train import SwinPETModel, MSESSIMLoss
from tqdm import tqdm

def parse_arguments():
    parser = argparse.ArgumentParser(description="training codes")
    parser.add_argument("--output", type=str, default="../results/model_default", help="Path to save checkpoint.")
    parser.add_argument("--input", type=str, default="../mat/NAC_test", help="Input images.")
    parser.add_argument("--target", type=str, default="../mat/CT_test", help="Target images.")
    parser.add_argument("--model", type=str, default="../models/model_default/checkpoint/latest.pth")
    args = parser.parse_args()
    return args

def init_status(args):
    os.makedirs(args.output, exist_ok=True)
    os.makedirs(os.path.join(args.output, "predict"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "target"), exist_ok=True)
    os.makedirs(os.path.join(args.output, "origin"), exist_ok=True)

def eval(args):
    # ğŸ§  2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
    model = SwinPETModel()
    # åŠ è½½æ¨¡å‹æƒé‡å­—å…¸
    checkpoint = torch.load(args.model, map_location='cpu')
    criterion = MSESSIMLoss()

    # å¤„ç† state_dictï¼Œç§»é™¤ 'module.' å‰ç¼€
    new_state_dict = {}
    for k, v in checkpoint.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # å»æ‰ 'module.' å‰ç¼€
        else:
            new_state_dict[k] = v

    # å°†æ–° state_dict åŠ è½½åˆ°æ¨¡å‹ä¸­
    model.load_state_dict(new_state_dict)
    model.eval()  # è®¾ä¸ºæ¨ç†æ¨¡å¼
    
    # ğŸŒˆ 3. å®šä¹‰å›¾åƒé¢„å¤„ç†æ–¹æ³• (ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´)
    transform = transforms.Compose([
        transforms.Resize((224, 224))
    ])
    
    input_folder = args.input  # å­˜æ”¾ .mat æ–‡ä»¶çš„æ–‡ä»¶å¤¹
    target_folder = args.target  # æœŸæœ›è¾“å‡ºå›¾ç‰‡
    output_folder = args.output  # é¢„æµ‹è¾“å‡ºå›¾ç‰‡çš„ä¿å­˜æ–‡ä»¶å¤¹
    
    loss_total = 0
    
    for file_name in tqdm(os.listdir(input_folder)):
        input_path = os.path.join(input_folder, file_name)
        target_path = os.path.join(target_folder, file_name)
        
        # è¯»å– .mat æ–‡ä»¶ä¸­çš„å›¾åƒæ•°æ® (å‡è®¾ img å­—æ®µåŒ…å« 256x256 çš„ç°åº¦å›¾ï¼ŒèŒƒå›´ä¸º 0-1)
        input_img = io.loadmat(input_path)['img'].astype('float32')
        input_img = np.repeat(input_img[:,:,np.newaxis], 3, axis=2)
        input_img = torch.from_numpy(input_img).permute(2, 0, 1).float()
        input_img = transform(input_img).unsqueeze(0)
        
        target_img = io.loadmat(target_path)['img'].astype('float32')
        target_img = torch.from_numpy(target_img).unsqueeze(0).float()
        target_img = transform(target_img.repeat(3, 1, 1))[0:1, :, :].unsqueeze(0)
        
        # è¿›è¡Œæ¨ç†
        with torch.no_grad():
            output = model(input_img)
        
        loss = criterion(output, target_img)
        loss_total += loss
        
        # å¤„ç†è¾“å‡º (è½¬æ¢ä¸ºå›¾åƒ)
        output = output.squeeze(0).squeeze(0).numpy()  # å½¢çŠ¶ (224, 224)
        output = (output - output.min()) / (output.max() - output.min())  # å½’ä¸€åŒ–åˆ° 0-1
        output = (output * 255).astype(np.uint8)
        
        # ä¿å­˜è¾“å‡ºå›¾åƒ
        output_path = os.path.join(output_folder, "predict", f"{os.path.splitext(file_name)[0]}.png")
        cv2.imwrite(output_path, output)
        
    print(f"All precessed loss: {loss_total / len(os.listdir(input_folder))}")

if __name__ == "__main__":
    args = parse_arguments()
    init_status(args)
    eval(args)